{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ammar11232/Detection-AI-Generated-Arabic-Text/blob/main/Data%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz226TxDVrrT"
      },
      "outputs": [],
      "source": [
        "#Phase 1.2\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dXn0AI6Sch5"
      },
      "outputs": [],
      "source": [
        "#Phase 1.2\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awdfgAz7ScfC"
      },
      "outputs": [],
      "source": [
        "#Phase 1.2\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3FhNQbiSccL"
      },
      "outputs": [],
      "source": [
        "#Phase 1.2\n",
        "dataset = load_dataset(\"KFUPM-JRCAI/arabic-generated-abstracts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmz5-dglScZD"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nvgk8MQScWc"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "df1 = pd.DataFrame(dataset['by_polishing'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNsl0WQyScTX"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "df2 = pd.DataFrame(dataset['from_title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQaZq17RScLj"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "df3 = pd.DataFrame(dataset['from_title_and_content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1GmoJJwSYeS"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9L7k51eOPcM"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WAGnLpoS0an"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KExjGNJAS25-"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc1ULrPDS4mz"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZmvl5-zS4dd"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvMk5IZuYGpu"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIZeqz4W433_"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "human_df = pd.DataFrame({\n",
        "    \"abstract\": df[\"original_abstract\"],\n",
        "    \"label\": \"Human\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8m6HjTbrk3p"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "ai_texts = pd.concat([\n",
        "    df[\"allam_generated_abstract\"],\n",
        "    df[\"jais_generated_abstract\"],\n",
        "    df[\"llama_generated_abstract\"],\n",
        "    df[\"openai_generated_abstract\"]\n",
        "], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEPOyTyqwPBp"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "ai_df = pd.DataFrame({\n",
        "    \"abstract\": ai_texts,\n",
        "    \"label\": \"AI\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCgyUcrCwPGS"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "full_df = pd.concat([human_df, ai_df], ignore_index=True)\n",
        "\n",
        "print(full_df.head())\n",
        "print(full_df[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlw5JR7AwM0k"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(df.duplicated(['original_abstract']).sum())\n",
        "print(df.duplicated(['allam_generated_abstract']).sum())\n",
        "print(df.duplicated(['jais_generated_abstract']).sum())\n",
        "print(df.duplicated(['llama_generated_abstract']).sum())\n",
        "print(df.duplicated(['openai_generated_abstract']).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxfN2QHj5wyo"
      },
      "outputs": [],
      "source": [
        "#Phase 1.3\n",
        "print(full_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VgWW1aioFrI"
      },
      "outputs": [],
      "source": [
        "#Phase 2.1\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from datasets import load_dataset\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fssq1OOsKH5L"
      },
      "outputs": [],
      "source": [
        "#Phase 2.1\n",
        "print(full_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBSkGdPpo7wb"
      },
      "outputs": [],
      "source": [
        "#Phase 2.1\n",
        "def remove_diacritics(text):\n",
        "    arabic_diacritics = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
        "    return re.sub(arabic_diacritics, '', text)\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"[^؀-ۿ ]+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "stemmer = ISRIStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text)\n",
        "    text = remove_diacritics(text)\n",
        "    text = normalize_arabic(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in arabic_stopwords]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yznUzomat4_4"
      },
      "outputs": [],
      "source": [
        "#Phase 2.1\n",
        "full_df[\"abstract_clean\"] = full_df[\"abstract\"].apply(preprocess_text)\n",
        "full_df.head(2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FomGHBIoP3hi"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzBocFj0P85R"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "def text_stats(texts):\n",
        "    words = [w for txt in texts for w in txt.split()]\n",
        "    avg_word_len = np.mean([len(w) for w in words])\n",
        "    avg_sent_len = np.mean([len(txt.split()) for txt in texts])\n",
        "    vocab = set(words)\n",
        "    ttr = len(vocab) / len(words)\n",
        "    return avg_word_len, avg_sent_len, ttr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSraoDsBQBGp"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "stats_human = text_stats(df[\"original_abstract\"])\n",
        "stats_ai = text_stats(ai_texts)\n",
        "print(\"\\n Statistical Summary:\")\n",
        "print(f\"Human-written: Avg word len={stats_human[0]:.2f}, Avg sent len={stats_human[1]:.2f}, TTR={stats_human[2]:.3f}\")\n",
        "print(f\"AI-generated : Avg word len={stats_ai[0]:.2f}, Avg sent len={stats_ai[1]:.2f}, TTR={stats_ai[2]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J21yML0gRIJC"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"human_length\"] = df[\"original_abstract\"].apply(lambda x: len(x.split()))\n",
        "df[\"ai_length\"] = ai_texts.apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(df[\"human_length\"], bins=30, alpha=0.6, label=\"Human-written\", color='blue')\n",
        "plt.hist(df[\"ai_length\"], bins=30, alpha=0.6, label=\"AI-generated\", color='orange')\n",
        "plt.xlabel(\"Sentence Length (words)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qhmO7EEAPkS"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "def type_token_ratio(text):\n",
        "    words = text.split()\n",
        "    return len(set(words)) / len(words) if words else 0\n",
        "\n",
        "df[\"human_ttr\"] = df[\"original_abstract\"].apply(type_token_ratio)\n",
        "df[\"ai_ttr\"] = ai_texts.apply(type_token_ratio)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.boxplot([df[\"human_ttr\"], df[\"ai_ttr\"]], labels=[\"Human\", \"AI\"])\n",
        "plt.title(\"Vocabulary Richness (Type–Token Ratio)\")\n",
        "plt.ylabel(\"TTR Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 2.2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def plot_top_ngrams(texts, n=2, top_k=10, label=\"Dataset\"):\n",
        "    texts = texts.dropna().astype(str)\n",
        "\n",
        "    vec = CountVectorizer(ngram_range=(n, n))\n",
        "    bag = vec.fit_transform(texts)\n",
        "\n",
        "    if bag.shape[1] == 0:\n",
        "        print(f\"No {n}-grams found for {label}.\")\n",
        "        return\n",
        "\n",
        "    sum_words = bag.sum(axis=0)\n",
        "    freqs = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    freqs = sorted(freqs, key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "    words, counts = zip(*freqs)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.barplot(x=list(counts), y=list(words))\n",
        "    plt.title(f\"Top {top_k} {n}-grams for {label} abstracts\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EtpywWG8-vrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_top_ngrams(df[\"original_abstract\"], n=2, label=\"Human\")\n"
      ],
      "metadata": {
        "id": "P7jWtdI__rtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm5ib1qbEzS2"
      },
      "outputs": [],
      "source": [
        "#Phase 2.2\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "human_words = \" \".join(df[\"original_abstract\"]).split()\n",
        "ai_words = \" \".join(ai_texts).split()\n",
        "\n",
        "human_freq = Counter(human_words)\n",
        "ai_freq = Counter(ai_words)\n",
        "\n",
        "common_words = set(list(human_freq.keys())[:100]) & set(list(ai_freq.keys())[:100])\n",
        "\n",
        "data = []\n",
        "for w in common_words:\n",
        "    data.append((w, human_freq[w], ai_freq[w]))\n",
        "\n",
        "freq_df = pd.DataFrame(data, columns=[\"word\", \"Human\", \"Ai\"]).sort_values(\"Human\", ascending=False)[:15]\n",
        "\n",
        "freq_df.plot(x=\"word\", kind=\"bar\", figsize=(20,4), title=\"Top Words: Human vs AI\", rot=45)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKfT5Lx8PgFw"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "import regex as re2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJiuJGrDLMj9"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1\n",
        "def simple_word_tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize text into words / symbols with Arabic support.\n",
        "    \"\"\"\n",
        "    return re2.findall(r\"\\p{Arabic}+|\\w+|[^\\s\\w]\", text, flags=re2.VERSION1)\n",
        "\n",
        "def sentence_tokenize(text):\n",
        "    \"\"\"\n",
        "    Split text into sentences using Arabic/English punctuation.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    parts = re.split(r'(?<=[\\.\\?\\!\\u061F\\u061B])\\s+', text)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "def paragraph_tokenize(text):\n",
        "    \"\"\"\n",
        "    Split text into paragraphs based on double newlines.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    paragraphs = re.split(r'\\s*\\n\\s*\\n\\s*|\\s*\\r\\n\\s*\\r\\n\\s*', text.strip())\n",
        "    return [p.strip() for p in paragraphs if p.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91Ra8erxye_V"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1\n",
        "original_text_col = \"abstract\"\n",
        "clean_text_col = \"abstract_clean\"\n",
        "\n",
        "full_df[\"tokens\"] = full_df[clean_text_col].apply(\n",
        "    lambda t: [tok for tok in simple_word_tokenize(t) if tok.strip()] if isinstance(t, str) else []\n",
        ")\n",
        "\n",
        "full_df[\"words\"] = full_df[\"tokens\"].apply(\n",
        "    lambda toks: [tok for tok in toks if re.search(r'\\w', tok)]\n",
        ")\n",
        "\n",
        "full_df[\"sentences\"] = full_df[original_text_col].apply(sentence_tokenize)\n",
        "\n",
        "full_df[\"paragraphs\"] = full_df[original_text_col].apply(paragraph_tokenize)\n",
        "\n",
        "print(\"Feature engineering completed! Columns now:\")\n",
        "print(full_df.columns)\n",
        "full_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcJoyPtqQvd8"
      },
      "outputs": [],
      "source": [
        "#Phase3.1 Feature 16: Number of words with repeated letters\n",
        "feature_name = f'{clean_text_col}_f016_words_with_repeated_letters'\n",
        "\n",
        "def _words_with_repeated_letters(words):\n",
        "    \"\"\"Counts words containing at least one pair of adjacent identical letters.\"\"\"\n",
        "    if not words:\n",
        "        return 0\n",
        "    return sum(1 for w in words if re.search(r'(.)\\1', w))\n",
        "\n",
        "full_df[feature_name] = full_df[\"words\"].apply(_words_with_repeated_letters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFKqdGv2kCPr"
      },
      "outputs": [],
      "source": [
        "#Phase3.1 Feature 34: 34. Total number of sentences (S)\n",
        "full_df['f034_Total_number_of_sentences_(S)'] = full_df[\"sentences\"].apply(len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u7_MQoMbQgu"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1 Feature 39: Average number of words/ S\n",
        "full_df['f039_Average_words_per_sentence'] = full_df.apply(\n",
        "    lambda row: len(row['words']) / row['f034_Total_number_of_sentences_(S)']\n",
        "    if row['f034_Total_number_of_sentences_(S)'] > 0 else 0,\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucs402e_S3Zu"
      },
      "outputs": [],
      "source": [
        "#Phase3.1 Feature 62: Number of imperfective\n",
        "col = original_text_col\n",
        "morph_features_col = f'{col}_morph_features'\n",
        "\n",
        "if morph_features_col in full_df.columns:\n",
        "    full_df[f'{col}_f062_num_imperfective'] = full_df[morph_features_col].apply(\n",
        "        lambda d: sum(1 for perf in d.get('is_perfective', []) if not perf)\n",
        "    )\n",
        "else:\n",
        "    full_df[f'{col}_f062_num_imperfective'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9dWaTn0_OmF"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1 Feature 85: Sentence Length Variance: Variance in the number of words per sentence.\n",
        "def sentence_length_variance(text):\n",
        "    sentences = sentence_tokenize(text)\n",
        "    if len(sentences) <= 1:\n",
        "        return 0\n",
        "    lengths = [len(s.split()) for s in sentences]\n",
        "    mean_len = sum(lengths) / len(lengths)\n",
        "    return sum((l - mean_len) ** 2 for l in lengths) / len(lengths)\n",
        "\n",
        "col = original_text_col\n",
        "feature_name = f\"{col}_f085_sentence_length_variance\"\n",
        "\n",
        "full_df[feature_name] = full_df[col].apply(sentence_length_variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3CwD7fkA52K"
      },
      "outputs": [],
      "source": [
        "#Phase 3.1 Feature 108: Politeness Score: Measures politeness.\n",
        "polite_words = [\n",
        "    \"من فضلك\", \"شكراً\", \"لو سمحت\", \"عفواً\",\n",
        "    \"من فضل حضرتك\", \"تكرماً\", \"فضلاً\", \"شاكراً لك\",\n",
        "    \"مع الشكر\", \"أكون لك من الشاكرين\", \"متفضلاً\",\n",
        "    \"أرجوك\", \"لطفاً\", \"إذا سمحت\", \"لو تكرمت\",\n",
        "    \"شكراً جزيلاً\", \"جزاك الله خيراً\", \"بارك الله فيك\",\n",
        "    \"شكراً لك\", \"أشكرك\", \"ممتن لك\", \"أكون ممتناً\",\n",
        "    \"تفضّل\", \"من لطفك\", \"يسعدني\", \"أتمنى منك\",\n",
        "    \"لو سمحتم\", \"لو تفضلتم\", \"بكل لطف\", \"كل الاحترام\"\n",
        "]\n",
        "def politeness_score(text):\n",
        "    if not isinstance(text, str) or len(text) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        count = sum(text.count(word) for word in polite_words)\n",
        "        total_words = len(simple_word_tokenize(text))\n",
        "        return (count / total_words) if total_words > 0 else 0.0\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "col = original_text_col\n",
        "feature_name = f'{col}_f108_politeness_score'\n",
        "\n",
        "full_df[feature_name] = full_df[col].apply(politeness_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjs3fh64Voeh"
      },
      "outputs": [],
      "source": [
        "#Phase 3.2\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, temp_df = train_test_split(\n",
        "    full_df,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF-yyeN8a0W1"
      },
      "outputs": [],
      "source": [
        "#Phase 3.2\n",
        "print(\"TOTAL:\", len(full_df))\n",
        "print(\"TRAIN:\", len(train_df))\n",
        "print(\"VAL:\", len(val_df))\n",
        "print(\"TEST:\", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKGi5vO4BJ8V"
      },
      "outputs": [],
      "source": [
        "#Phase 3.2\n",
        "full_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xlsxwriter"
      ],
      "metadata": {
        "id": "bgu-vnuzfFQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = \"processed data1.xlsx\"\n",
        "full_df.head.to_excel(output_file, index=False, engine='xlsxwriter')\n"
      ],
      "metadata": {
        "id": "ID6EpS6sfL1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bru1InwGx4sJ"
      },
      "outputs": [],
      "source": [
        "#Phase 4\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    analyzer='word'\n",
        ")\n",
        "\n",
        "tfidf_vectorizer.fit(train_df[\"abstract_clean\"])\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.transform(train_df[\"abstract_clean\"])\n",
        "X_val_tfidf   = tfidf_vectorizer.transform(val_df[\"abstract_clean\"])\n",
        "X_test_tfidf  = tfidf_vectorizer.transform(test_df[\"abstract_clean\"])\n",
        "\n",
        "print(\"TF-IDF shapes:\")\n",
        "print(\"Train:\", X_train_tfidf.shape)\n",
        "print(\"Validation:\", X_val_tfidf.shape)\n",
        "print(\"Test:\", X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YirYZX6Eg0rC"
      },
      "outputs": [],
      "source": [
        "#Phase 4\n",
        "\n",
        "from scipy.sparse import hstack\n",
        "EXCLUDED_COLS = [\n",
        "    'label',\n",
        "    'abstract',\n",
        "    'abstract_clean',\n",
        "    'tokens',\n",
        "    'words',\n",
        "    'sentences',\n",
        "    'paragraphs'\n",
        "]\n",
        "\n",
        "numeric_cols = [\n",
        "    col for col in train_df.select_dtypes(include=np.number).columns\n",
        "    if col not in EXCLUDED_COLS\n",
        "]\n",
        "\n",
        "X_train_num_array = train_df[numeric_cols].values\n",
        "X_val_num_array   = val_df[numeric_cols].values\n",
        "X_test_num_array  = test_df[numeric_cols].values\n",
        "\n",
        "X_train = hstack([X_train_tfidf, X_train_num_array])\n",
        "X_val   = hstack([X_val_tfidf,   X_val_num_array])\n",
        "X_test  = hstack([X_test_tfidf,  X_test_num_array])\n",
        "\n",
        "y_train = train_df[\"label\"]\n",
        "y_val   = val_df[\"label\"]\n",
        "y_test  = test_df[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PV9ESZ81Vwq"
      },
      "outputs": [],
      "source": [
        "#Phase 4\n",
        "\n",
        "print(\"X and y are ready for ML models.\")\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation:\", X_val.shape, y_val.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf8iFntaiwvO"
      },
      "outputs": [],
      "source": [
        "#Phase 4.1\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=3000, random_state=42)\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = lr_model.predict(X_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report (Validation):\")\n",
        "print(classification_report(y_val, y_val_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxRCNpd61hcQ"
      },
      "outputs": [],
      "source": [
        "#Phase 4.1\n",
        "\n",
        "y_test_pred = lr_model.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwNBUAhXFUUa"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du2LtfDBAU7m"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "models = {}\n",
        "\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8ByTLdcAUzY"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "y_val_pred_svm = svm_model.predict(X_val)\n",
        "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, y_val_pred_svm))\n",
        "print(classification_report(y_val, y_val_pred_svm))\n",
        "\n",
        "models['SVM'] = svm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__-S-picITPB"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PAvAIIAAnLI"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "print(\"Random Forest Validation Accuracy:\", accuracy_score(y_val, y_val_pred_rf))\n",
        "print(classification_report(y_val, y_val_pred_rf))\n",
        "\n",
        "models['RandomForest'] = rf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1k0oJcCF4oo"
      },
      "outputs": [],
      "source": [
        "#Phase 4.2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "model_names = ['SVM', 'RandomForest']\n",
        "\n",
        "for name in model_names:\n",
        "    model = models[name]\n",
        "\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n===== {name} Test Evaluation =====\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERBtGcf7GBtm"
      },
      "outputs": [],
      "source": [
        "#Phase 4.3\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "bert_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "X_train_emb = bert_model.encode(\n",
        "    train_df[\"abstract_clean\"].tolist(),\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "X_val_emb = bert_model.encode(\n",
        "    val_df[\"abstract_clean\"].tolist(),\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "X_test_emb = bert_model.encode(\n",
        "    test_df[\"abstract_clean\"].tolist(),\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "y_train = train_df[\"label\"].values\n",
        "y_val = val_df[\"label\"].values\n",
        "y_test = test_df[\"label\"].values\n",
        "\n",
        "print(\"Train embedding shape:\", X_train_emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 4.3\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "ffnn_model = models.Sequential([\n",
        "    layers.Input(shape=(X_train_emb.shape[1],)),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "ffnn_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "ffnn_model.summary()"
      ],
      "metadata": {
        "id": "nqEijVOalvxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 4.3\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "tf.config.optimizer.set_jit(False)\n",
        "\n",
        "\n",
        "\n",
        "#  Convert embeddings & labels to correct dtype\n",
        "X_train_emb = X_train_emb.astype(\"float32\")\n",
        "X_val_emb   = X_val_emb.astype(\"float32\")\n",
        "X_test_emb  = X_test_emb.astype(\"float32\")\n",
        "\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val   = label_encoder.transform(y_val)\n",
        "y_test  = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert to int32 required by TensorFlow\n",
        "y_train = y_train.astype(\"int32\")\n",
        "y_val   = y_val.astype(\"int32\")\n",
        "y_test  = y_test.astype(\"int32\")\n",
        "\n",
        "print(\"Encoded classes:\", label_encoder.classes_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ANujnVa6okJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 4.3\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"best_ffnn_bert.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = ffnn_model.fit(\n",
        "    X_train_emb, y_train,\n",
        "    validation_data=(X_val_emb, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    verbose=2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "r1fNHKbbo3sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 4.3\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_test_pred_prob = ffnn_model.predict(X_test_emb)\n",
        "y_test_pred = (y_test_pred_prob > 0.5).astype(\"int32\").ravel()\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "CumT3UWKpXB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 4.4\n",
        "import os\n",
        "import joblib\n",
        "from tensorflow.keras.models import Model as KerasModel\n",
        "\n",
        "def save_all_models(models_dict, save_dir=\"models\"):\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for model_name, model_obj in models_dict.items():\n",
        "\n",
        "        if isinstance(model_obj, KerasModel):\n",
        "            file_path = os.path.join(save_dir, f\"{model_name}.h5\")\n",
        "            model_obj.save(file_path)\n",
        "            print(f\"[Saved] Keras model → {file_path}\")\n",
        "\n",
        "        else:\n",
        "            file_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n",
        "            joblib.dump(model_obj, file_path)\n",
        "            print(f\"[Saved] Pickle model → {file_path}\")\n",
        "\n",
        "    print(\"\\nAll models saved successfully!\")"
      ],
      "metadata": {
        "id": "QIg-Cienp4d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYiwfQ4LH2sK"
      },
      "outputs": [],
      "source": [
        "#Phase 4.4\n",
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "models_dict = {\n",
        "    \"lr_model\": lr_model,\n",
        "    \"svm\": svm_model,\n",
        "    \"random_forest\": rf_model,\n",
        "    \"ffnn\": ffnn_model\n",
        "}\n",
        "\n",
        "save_all_models(models_dict)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}